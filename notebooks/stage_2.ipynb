{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Eksploracja Danych - Projekt\n",
    "Tomasz Kiljańczyk (136257)\n",
    "\n",
    "Wojciech Lulek (136280)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "us_trending_df = pd.read_csv('./data/us_trending_stage_1.csv').head(1000)\n",
    "us_trending_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "us_trending_df['thumbnail_link_hires'] = us_trending_df['thumbnail_link'].str.replace('default.jpg', '0.jpg')\n",
    "us_trending_df['thumbnail_link_hires']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks.workers import download_and_save\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./images/'):\n",
    "    os.makedirs('./images/')\n",
    "\n",
    "data = us_trending_df['thumbnail_link_hires'].unique()\n",
    "with Pool(processes=os.cpu_count()) as pool:\n",
    "    for _ in tqdm_notebook(pool.imap(download_and_save, data), total=data.size):\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks.workers import extract_color_features\n",
    "from PIL import Image\n",
    "\n",
    "image_dataframe = pd.DataFrame(columns=[\n",
    "    'thumbnail_med_hue',\n",
    "    'thumbnail_med_saturation',\n",
    "    'thumbnail_med_value',\n",
    "    'thumbnail_avg_hue',\n",
    "    'thumbnail_avg_saturation',\n",
    "    'thumbnail_avg_value',\n",
    "    'thumbnail_colorfulness'\n",
    "])\n",
    "\n",
    "data = us_trending_df['thumbnail_link_hires'].unique()\n",
    "results = []\n",
    "\n",
    "with Pool(processes=os.cpu_count()) as pool:\n",
    "    for res in tqdm_notebook(pool.imap(extract_color_features, data), total=data.size):\n",
    "        results.append(res)\n",
    "\n",
    "color_features_dict = dict(results)\n",
    "\n",
    "color_features = [color_features_dict[url] for url in us_trending_df['thumbnail_link_hires']]\n",
    "\n",
    "image_dataframe = image_dataframe.append(color_features, ignore_index=True)\n",
    "image_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_concat_h(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "\n",
    "for i, url in enumerate(us_trending_df['thumbnail_link_hires'].head(5)):\n",
    "    file_path = f'./images/{url.split(\"/\")[-2]}.jpg'\n",
    "\n",
    "    image = Image.open(file_path)\n",
    "\n",
    "    row = image_dataframe.iloc[i]\n",
    "    median_hsv_color = (\n",
    "        round(row['thumbnail_med_hue']),\n",
    "        round(row['thumbnail_med_saturation']),\n",
    "        round(row['thumbnail_med_value'])\n",
    "    )\n",
    "    avg_hsv_color = (\n",
    "        round(row['thumbnail_avg_hue']),\n",
    "        round(row['thumbnail_avg_saturation']),\n",
    "        round(row['thumbnail_avg_value'])\n",
    "    )\n",
    "\n",
    "    dims = (round(image.width * 0.1), image.height)\n",
    "    median_color_image = Image.new('HSV', dims, color=median_hsv_color).convert('RGB')\n",
    "    average_color_image = Image.new('HSV', dims, color=avg_hsv_color).convert('RGB')\n",
    "\n",
    "    image_result_1 = get_concat_h(image, median_color_image)\n",
    "    image_result_1 = get_concat_h(image_result_1, average_color_image)\n",
    "\n",
    "    display(image_result_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks.workers import detect_text\n",
    "\n",
    "results = []\n",
    "with Pool(processes=os.cpu_count()) as pool:\n",
    "    data = us_trending_df['thumbnail_link_hires'].unique()\n",
    "    for res in tqdm_notebook(pool.imap(detect_text, data), total=data.size):\n",
    "        results.append(res)\n",
    "\n",
    "has_text_dict = dict(results)\n",
    "has_text = [has_text_dict.get(url, False) for url in us_trending_df['thumbnail_link_hires']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notatki:\n",
    "* można spróbować cechy z bounding boxów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "has_text_df = pd.DataFrame(has_text, columns=['has_text'])\n",
    "has_text_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df = pd.concat([us_trending_df, image_dataframe], axis=1)\n",
    "final_df = pd.concat([final_df, has_text_df], axis=1)\n",
    "final_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corrMatrix = final_df.corr(method='spearman')\n",
    "corrMatrix = corrMatrix.round(4)\n",
    "\n",
    "mask = np.triu(np.ones_like(corrMatrix, dtype=bool))\n",
    "np.fill_diagonal(mask, False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(corrMatrix, mask=mask, annot=True, fmt='g', ax=ax)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df.to_csv(\"./us_trending_stage_2_tk.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using ImageAI for object detection\n",
    "\n",
    "Trained model file is required! Put this into notebooks/models directory. Download link: https://github.com/OlafenwaMoses/ImageAI/releases/download/essentials-v5/resnet50_coco_best_v2.1.0.h5/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading pre-trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath(\"models/resnet50_coco_best_v2.1.0.h5\")\n",
    "detector.loadModel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Detecting objects from thumbnails"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "dir_name = \"images\"\n",
    "dir_filenames = os.listdir(dir_name)\n",
    "dir_filenames.remove(\".gitignore\")\n",
    "images_left = len(dir_filenames)\n",
    "image_detections = dict()\n",
    "\n",
    "for filename in tqdm.tqdm(dir_filenames):\n",
    "    detections = detector.detectObjectsFromImage(input_image=f\"{dir_name}/\" + filename, output_type=\"array\")[1]\n",
    "    image_detections[filename] = detections\n",
    "\n",
    "    images_left -= 1\n",
    "    if images_left % 500 == 0:\n",
    "        print(\"Backup\")\n",
    "        with open(\"data/thumbnails_objects_dict.pkl\", \"wb\") as f:\n",
    "            pickle.dump(image_detections, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading detections from pickle file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/thumbnails_objects_dict.pkl\", \"rb\") as f:\n",
    "    image_detections = dict(pickle.load(f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Counting detected objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_objects_detected = dict()\n",
    "counts = dict()\n",
    "\n",
    "for key in image_detections.keys():\n",
    "    image_objects_detected[key] = dict()\n",
    "\n",
    "    for obj in image_detections[key]:\n",
    "        name = obj['name']\n",
    "        image_objects_detected[key][name] = image_objects_detected[key].get(name, 0) + 1\n",
    "        counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "counts = dict(reversed(sorted(counts.items(), key=lambda item: item[1])))\n",
    "top_popular_objects = list(counts.keys())[:10]\n",
    "\n",
    "print(\"counts\", counts)\n",
    "print(\"10 most common objects:\", top_popular_objects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating vector representation and saving it to data/ in CSV format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(image_objects_detected).transpose()\n",
    "df = df.fillna(0)\n",
    "df = df.astype('int32')\n",
    "\n",
    "df.to_csv(\"data/thumbnails_objects_vectors.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notatka: Może wagi wilkością bboxów\n",
    "\n",
    "może rozpoznawanie emocji na twarzach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}